# -----------------------------
# docker-compose.yml (Flink + Iceberg Setup)
# -----------------------------
version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - flinknetwork


  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - flinknetwork

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    container_name: schema-registry
    depends_on:
      - kafka
    ports:
      - "8084:8084"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8084
    networks:
      - flinknetwork

  connect:
    image: cnfldemos/kafka-connect-datagen:0.4.0-6.1.0
    container_name: connect
    depends_on:
      - kafka
      - schema-registry
    ports:
      - "8083:8083"
    volumes:
      - ./schemas:/schemas
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8084
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
    networks:
      - flinknetwork
      
  jobmanager:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    volumes:
      - ./flink-conf.yaml:/opt/flink/conf/flink-conf.yaml
      - ./iceberg-warehouse:/opt/warehouse
      - ./hive-conf:/opt/hive-conf
      - ./sql-client-intialization.sql:/opt/flink/sql-client-intialization.sql
    depends_on:
      - kafka
    networks:
      - flinknetwork

  taskmanager:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: flink-taskmanager
    depends_on:
      - jobmanager
    command: taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    volumes:
      - ./flink-conf.yaml:/opt/flink/conf/flink-conf.yaml
      - ./iceberg-warehouse:/opt/warehouse
      - ./hive-conf:/opt/hive-conf
      - ./sql-client-intialization.sql:/opt/flink/sql-client-intialization.sql
    networks:
      - flinknetwork


  postgres:
    image: postgres:13
    container_name: postgres
    restart: always
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
    ports:
      - "5432:5432"
    networks:
      - flinknetwork


  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    depends_on:
      - postgres
    ports:
      - "9083:9083"
    environment:
      SERVICE_NAME: metastore
      HIVE_METASTORE_DB_TYPE: postgres
    volumes:
      - ./iceberg-warehouse:/opt/warehouse
      - ./hive-conf:/opt/hive-conf
    networks:
      - flinknetwork

  
  spark-hive-client:
    image: bitnami/spark:3.3.2
    container_name: spark-hive-client
    depends_on:
      - hive-metastore
    command: tail -f /dev/null
    volumes:
      - ./hive-conf:/opt/hive-conf
      - ./iceberg-warehouse:/opt/warehouse
      - ./hive-conf/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    environment:
      - SPARK_EXTRA_CLASSPATH=/opt/hive-conf
      - HOME=/tmp
    networks:
      - flinknetwork



networks:
  flinknetwork:
    name: flinknetwork
